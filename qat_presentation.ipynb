{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de4668b-676b-4b28-8007-6cd234f840fc",
   "metadata": {},
   "source": [
    "# Target\n",
    "**Objective**:\n",
    "\n",
    "Optimize ResNet18 (CIFAR-10) from FP32 to INT8 with minimal accuracy degradation, and provide comparisons on model size, latency, throughput, and accuracy.\n",
    "\n",
    "**Deliverables**:\n",
    "\n",
    "1. FP32 baseline, PTQ model, and QAT model\n",
    "2. TorchScript/ONNX exports\n",
    "3. Standardized benchmarking scripts with tables and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656861c-5c63-4e71-836b-914aa1bfc827",
   "metadata": {},
   "source": [
    "# 1. Environment\n",
    "Python 3.10+, PyTorch ≥ 2.2（torch.ao.quantization）, torchvision, onnx, onnxruntime, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa1d1b-0be7-46c8-b547-c1e303a2c799",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Train/Test Split: torchvision.datasets.CIFAR10\n",
    "2. Recommended Transforms:\n",
    "   + Training: RandomCrop(32, 4), RandomHorizontalFlip(), ToTensor(), Normalize(mean, std)\n",
    "   + Test/Calibration: ToTensor(), Normalize(mean, std)\n",
    "3. Batch Sizes: train_bs = 128, test_bs = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e8212-ccc6-4d22-b560-85716d6968c3",
   "metadata": {},
   "source": [
    "**Preprocessing pipeline**\n",
    "\n",
    "This preprocessing pipeline converts CIFAR-10 (32×32, [0,1], NCHW) → (224×224, [-1,1], NHWC), fully aligned with the input specification of Keras ResNet50V2.\n",
    "+ For the training set, random cropping and horizontal flipping are added as augmentations\n",
    "+ For the test set, only resizing and normalization are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e6b7e8e-43a6-4a1e-b838-ed9daa654e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "\n",
    "# 1) 不做 Normalize（保持 [0,1]），保持你原来的增强\n",
    "train_transform_clean = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),                # -> [0,1], NCHW\n",
    "])\n",
    "test_transform_clean = T.Compose([\n",
    "    T.ToTensor(),                # -> [0,1]\n",
    "])\n",
    "\n",
    "root = \"/mnt/qat/cifar10\"\n",
    "train_set_clean = datasets.CIFAR10(root=root, train=True,  download=False, transform=train_transform_clean)\n",
    "test_set_clean  = datasets.CIFAR10(root=root, train=False, download=False, transform=test_transform_clean)\n",
    "\n",
    "# 2) 关键：DataLoader 用单进程，避免第二个 epoch 崩溃\n",
    "def make_torch_loaders(train_bs=128, test_bs=256):\n",
    "    train_loader = DataLoader(train_set_clean, batch_size=train_bs, shuffle=True,\n",
    "                              num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "    test_loader  = DataLoader(test_set_clean,  batch_size=test_bs, shuffle=False,\n",
    "                              num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 3) 生成器：NCHW -> NHWC，不做额外变量创建\n",
    "def torch_dl_generator(dl):\n",
    "    for x, y in dl:\n",
    "        yield x.permute(0, 2, 3, 1).numpy(), y.numpy()\n",
    "\n",
    "# 4) 把 PyTorch loader 包成 tf.data。注意：不要跨 epoch 复用，按 epoch 重建\n",
    "IMG = 224\n",
    "def map_fn(img, label):\n",
    "    img = tf.image.resize(img, (IMG, IMG))   # 32 -> 224\n",
    "    img = preprocess_input(img * 255.0)      # ResNet50V2 预处理\n",
    "    return img, tf.cast(label, tf.int32)\n",
    "\n",
    "def make_tf_dataset_from_loader(dl, batch_size):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: torch_dl_generator(dl),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None,),           dtype=tf.int64),\n",
    "        )\n",
    "    ).unbatch()\n",
    "    ds = (ds.map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46e1fe-e1d9-4036-95c5-5162dc97a201",
   "metadata": {},
   "source": [
    "# 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8b523-405e-4ad9-8d3a-4f2ea75aa156",
   "metadata": {},
   "source": [
    "## 2.1 load basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977e3a2e-94bb-4aa2-8833-95bc5d4c7430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e2963-f568-4df6-b220-364531b715c3",
   "metadata": {},
   "source": [
    "## 2.2 add classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e38f35-c5e9-4759-810b-1b312bbd8d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# 1) backbone\n",
    "base_model = ResNet50V2(include_top=False, weights=None,\n",
    "                        input_shape=(224, 224, 3), pooling=\"avg\")\n",
    "\n",
    "base_model.load_weights(\"resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "# 2) add classification layer\n",
    "x = layers.Dense(256, activation=\"relu\")(base_model.output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# 3) Freeze → Train the head, then fine-tune\n",
    "base_model.trainable = False\n",
    "model.compile(optimizer=optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ccdd8-318e-4fa0-b908-8cc2c25b7832",
   "metadata": {},
   "source": [
    "## 2.3 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402fe45f-7b74-4027-b4bd-dff12753d660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 批大小\n",
    "TRAIN_BS, TEST_BS = 64, 128\n",
    "EPOCHS = 5\n",
    "\n",
    "# 先做一次 test_ds（验证集不用每轮重建）\n",
    "_, test_loader = make_torch_loaders(TRAIN_BS, TEST_BS)\n",
    "test_ds = make_tf_dataset_from_loader(test_loader, TEST_BS)\n",
    "val_steps = len(test_loader)   \n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    # 关键：每个 epoch 重新创建 train_loader 和 train_ds\n",
    "    train_loader, _ = make_torch_loaders(TRAIN_BS, TEST_BS)\n",
    "    train_ds = make_tf_dataset_from_loader(train_loader, TRAIN_BS)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "\n",
    "    print(f\"\\n==== Epoch {ep+1}/{EPOCHS} ====\")\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=1,                         # 一次只跑1个epoch\n",
    "        steps_per_epoch=steps_per_epoch,  # 显式告知步数\n",
    "        validation_data=test_ds,\n",
    "        validation_steps=val_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4d2b9-7c5f-4f62-9d98-6a2c77361b2d",
   "metadata": {},
   "source": [
    "==== Epoch 1/5 ====\n",
    "  1/782 ━━━━━━━━━━━━━━━━━━━━ 4:18:21 20s/step - accuracy: 0.1094 - loss: 3.4535\n",
    "I0000 00:00:1758820413.279835    2695 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
    "782/782 ━━━━━━━━━━━━━━━━━━━━ 138s 152ms/step - accuracy: 0.8062 - loss: 0.5749 - val_accuracy: 0.8607 - val_loss: 0.3932\n",
    "\n",
    "==== Epoch 2/5 ====\n",
    "782/782 ━━━━━━━━━━━━━━━━━━━━ 91s 116ms/step - accuracy: 0.8489 - loss: 0.4453 - val_accuracy: 0.8738 - val_loss: 0.3567\n",
    "\n",
    "==== Epoch 3/5 ====\n",
    "782/782 ━━━━━━━━━━━━━━━━━━━━ 91s 116ms/step - accuracy: 0.8579 - loss: 0.4123 - val_accuracy: 0.8785 - val_loss: 0.3525\n",
    "\n",
    "==== Epoch 4/5 ====\n",
    " 51/782 ━━━━━━━━━━━━━━━━━━━━ 1:11 98ms/step - accuracy: 0.8640 - loss: 0.4066"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce762e-9ad5-4359-9432-e3080e148ec1",
   "metadata": {},
   "source": [
    "## 2.4 unfreeze the last few layers, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b058486c-3250-4aff-bc76-9269cf576f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, callbacks\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# 其他层/模型同理：from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c0ed6b-6e4a-477b-92b4-3a8943592f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    782/Unknown \u001b[1m120s\u001b[0m 137ms/step - accuracy: 0.8630 - loss: 0.4158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 172ms/step - accuracy: 0.8725 - loss: 0.3887 - val_accuracy: 0.8962 - val_loss: 0.2988 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8996 - loss: 0.3038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 155ms/step - accuracy: 0.9013 - loss: 0.3005 - val_accuracy: 0.9020 - val_loss: 0.3012 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9126 - loss: 0.2642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 156ms/step - accuracy: 0.9125 - loss: 0.2642 - val_accuracy: 0.9021 - val_loss: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9174 - loss: 0.2502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 158ms/step - accuracy: 0.9177 - loss: 0.2490 - val_accuracy: 0.9040 - val_loss: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9281 - loss: 0.2141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 157ms/step - accuracy: 0.9246 - loss: 0.2260 - val_accuracy: 0.9062 - val_loss: 0.3071 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, callbacks\n",
    "\n",
    "# 1) 解冻：只放开最后一个 stage（conv5），其余保持冻结\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers:\n",
    "    name = layer.name\n",
    "    # 冻结除 conv5_block* 以外的层；同时把 BN 全冻结（更稳）\n",
    "    if (\"conv5_block\" in name):\n",
    "        # conv5 的 BN 也建议不训练，避免统计量漂移\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# 2) 重新编译：小学习率 + label smoothing；可用 AdamW 稍微稳一点\n",
    "try:\n",
    "    from tensorflow_addons.optimizers import AdamW\n",
    "    opt = AdamW(learning_rate=2e-5, weight_decay=1e-4)\n",
    "except Exception:\n",
    "    opt = optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "\n",
    "# 选择一个优化器（冻结阶段用大点 LR，解冻微调用小点 LR）\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)   # 冻结阶段\n",
    "# 解冻微调时改成：opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "# 选择 loss（用 tf.keras 的枚举，兼容性最好）\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    # label_smoothing=0.1,  # 你的环境如果支持就保留；不支持就删掉\n",
    "    reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# 3) 回调（你可以沿用之前的）\n",
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(\"best_finetune.h5\", save_best_only=True,\n",
    "                              monitor=\"val_accuracy\", mode=\"max\"),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6),\n",
    "    callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=4, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "# 4) 微调开跑（3–6 个 epoch 通常够）\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=cbs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc14dfe-6951-4ffc-8c7a-ca6dd336b810",
   "metadata": {},
   "source": [
    "## 2.5 freeze BatchNorm (BN) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2f68127-3d4b-45cb-8d30-3abf1b338b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "    782/Unknown \u001b[1m124s\u001b[0m 140ms/step - accuracy: 0.9355 - loss: 0.1936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 172ms/step - accuracy: 0.9385 - loss: 0.1799 - val_accuracy: 0.9196 - val_loss: 0.2596 - learning_rate: 1.0000e-05\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9445 - loss: 0.1621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 154ms/step - accuracy: 0.9458 - loss: 0.1577 - val_accuracy: 0.9236 - val_loss: 0.2547 - learning_rate: 1.0000e-05\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9468 - loss: 0.1717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 154ms/step - accuracy: 0.9493 - loss: 0.1518 - val_accuracy: 0.9253 - val_loss: 0.2516 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fed45a9b5e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 冻结 BN 更稳\n",
    "for l in base_model.layers:\n",
    "    if isinstance(l, tf.keras.layers.BatchNormalization):\n",
    "        l.trainable = False\n",
    "\n",
    "# 小学习率\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),   # 如环境支持可加 label_smoothing=0.1\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "cbs = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_finetune.h5', save_best_only=True,\n",
    "                                       monitor='val_accuracy', mode='max'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                         patience=1, min_lr=1e-6),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3,\n",
    "                                     restore_best_weights=True),\n",
    "]\n",
    "model.fit(train_ds, epochs=3, validation_data=test_ds, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78dc092-9011-408a-b134-71e196738358",
   "metadata": {},
   "source": [
    "# 3. Base model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3221243f-a930-43c3-8d64-d3be93352471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"resnet50_fp32_baseline.h5\")               # 结构+权重\n",
    "# model.save_weights(\"resnet50_fp32_baseline_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b54b55-3741-4e41-9a24-24e33ce54f85",
   "metadata": {},
   "source": [
    "## 3.1 model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c72107f-ce2a-49ec-bedb-69f9a5990fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 跟保存时完全一致的结构\n",
    "base_model = ResNet50V2(include_top=False, weights=None,\n",
    "                        input_shape=(224, 224, 3), pooling=\"avg\")\n",
    "\n",
    "# 接分类头\n",
    "x = layers.Dense(256, activation=\"relu\")(base_model.output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a15701ef-273c-4d8a-9a00-6de50b7bb209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 推荐加载方式\n",
    "model.load_weights(\"resnet50_fp32_baseline.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510892cb-3eda-4c28-86f2-ffec6478797a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 23:03:25.581830: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "Keras from: /root/miniconda3/envs/myconda/lib/python3.10/site-packages/keras/_tf_keras/keras/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras   # ✅ 用 tf.keras 入口\n",
    "layers, models = keras.layers, keras.models\n",
    "\n",
    "print(\"TF:\", tf.__version__)            # 2.20.0\n",
    "print(\"Keras from:\", keras.__file__)    # 指向 site-packages/keras/..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aac8a2-ac04-4837-9f98-36607d58aa49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2 Record FP32 baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19bfe00d-41ee-481f-9acb-5b56fbe7ce04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 175ms/step - accuracy: 0.9253 - loss: 0.2516\n",
      "{'accuracy': 0.9253000020980835, 'loss': 0.2515576481819153}\n"
     ]
    }
   ],
   "source": [
    "# 记录 FP32 基线精度（后面对比）\n",
    "fp32_val = model.evaluate(test_ds, return_dict=True)\n",
    "print(fp32_val)  # {'loss': ..., 'accuracy': ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac60400-60a5-4d07-8fc4-55a6a695012c",
   "metadata": {},
   "source": [
    "# 4. Model Quantization with PTQ (Post-Training Quantization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906896b-1a2e-4d9d-bee4-e403c3639eaf",
   "metadata": {},
   "source": [
    "## 4.1 Dynamic Range\n",
    "\n",
    "PyTorch native quantization mainly targets CPU (x86 → FBGEMM; ARM → QNNPACK). For GPU, INT8 inference typically relies on TensorRT or ONNX Runtime EP.\n",
    "\n",
    "**Workflow：**\n",
    "\n",
    "1. Copy the FP32 model and apply fusion (Conv + BN + ReLU)\n",
    "2. Set backend and qconfig (use fbgemm for x86)\n",
    "3. Run prepare_fx (or prepare in eager mode)\n",
    "4. Calibration: run forward passes on 300–1000 representative samples (no backpropagation)\n",
    "5. convert_fx → obtain INT8 model\n",
    "6. Evaluation/benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af76a5ed-e0bb-453d-b1fa-d6085fa52a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8i9hgauo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8i9hgauo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp8i9hgauo'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140673706896448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706889056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707199120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707197360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707197184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707198416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707208976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707207392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707210560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707206160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707208800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706896624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707233648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707236816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707232416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707235056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707205984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707202816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707236640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707244384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707311344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707319088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707317504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707320672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707316272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707318912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707320496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705362528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705370976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705364288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705374672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705373440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705362880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705463120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705466288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705461888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705464528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705472800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705470688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705471568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705474208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705463824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706383792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706385728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706387488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706384848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706386256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706390656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705544160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705546800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705542048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705545392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705554896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705553312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705556480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705552080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705554720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706387312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706391008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705544512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705661488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705663424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705665184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705662544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705671696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705668704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705668000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705669584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705670464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705714336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705712752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705715920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705711520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705714160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705715744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705719440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705822864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705824624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705821984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705823392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705713456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705829552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705832720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705828320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705830960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705822512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705921344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705924512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705920112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705922752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705830256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705931024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705932960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705927856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705932080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705933488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705922048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705990400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705993568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705989168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705991808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705993392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706101216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706099808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706108256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706101568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706110192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706111952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706109312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706110720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706236336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706234752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706237920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706233872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706236160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706243552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533739952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706234224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533747168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533740480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533749104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533750864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533748224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533749632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533745408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533840544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533838080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533840368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533839664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533748752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533847584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533850752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533846352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533848992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533838784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533907488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533908544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533910304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533907664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533909072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533916816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533915232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533918400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533914000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533916640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533908192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534023408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534026576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534022176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534024816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534033088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534029920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534099872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534109024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534107440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534110608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534106208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534108848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534115536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534183376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534186016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534182144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534184608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534192528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534185840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534194464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534196224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534193584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534194992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534183728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534283264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534286432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534282032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534284672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534294528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534292944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534290832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534291712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534294352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534368352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534361664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534370288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534372048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534369408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534370816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534371872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534493440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534504528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534502944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534506112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534501712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534504352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534494144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534595616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534596672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534598432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534595792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534597200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534603360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534606352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534650576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534648992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534652160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534647760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534650400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534604944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534592976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534656208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399574720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399576480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399573840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399575248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399582992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399581408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399584576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399580176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399582816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399574368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399656816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399659984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399655584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399658224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399666496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399659808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399666320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399667728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399667552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399767456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399775200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399773616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399776784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399772384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399775024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399776608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399850784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399858704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399852016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399860640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399862400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399859760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399861168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399859936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400180048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400184976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400185680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758825704.212615    2644 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1758825704.212643    2644 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "I0000 00:00:1758825704.363328    2644 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24577728"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_dr = converter.convert()\n",
    "open(\"resnet50_ptq_dynamic.tflite\",\"wb\").write(tflite_dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0df1b-afe9-4aee-a4a7-5d0df9ee8e69",
   "metadata": {},
   "source": [
    "## 4.2 Full-Integer Quantization (INT8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e79dc6-9464-4ec1-908a-de3f0c3e7e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "N_SAMPLES = 512  # 推荐 200~1000\n",
    "\n",
    "def representative_gen():\n",
    "    # 用 tqdm 包装，显示进度\n",
    "    for i, (x, _) in enumerate(tqdm(test_ds.unbatch().take(N_SAMPLES),\n",
    "                                    total=N_SAMPLES,\n",
    "                                    desc=\"Calibrating\")):\n",
    "        yield [tf.cast(tf.expand_dims(x, 0), tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6af9d840-f459-4448-aee9-56d70b73cf8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbv0oliso/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbv0oliso/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpbv0oliso'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140673706896448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706889056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707199120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707197360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707197184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707198416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707208976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707207392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707210560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707206160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707208800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706896624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707233648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707236816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707232416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707235056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707205984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707202816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707236640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707244384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707243680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707311344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707319088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707317504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707320672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707316272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707318912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673707320496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705362528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705363056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705370976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705364288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705374672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705373440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705362880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705463120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705466288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705461888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705464528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705372560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705472800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705470688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705471568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705474208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705463824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706383792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706385728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706387488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706384848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706386256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706390656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705544160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705546800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705542048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705545392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705554896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705553312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705556480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705552080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705554720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706387312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706391008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705544512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705661488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705663424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705665184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705662544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705671696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705668704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705668000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705669584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705670464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705714336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705712752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705715920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705711520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705714160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705715744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705719440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705822864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705824624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705821984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705823392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705713456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705829552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705832720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705828320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705830960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705822512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705921344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705924512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705920112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705922752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705830256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705931024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705932960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705927856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705932080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705933488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705922048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705990400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705993568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705989168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705991808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673705993392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706101216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706099808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706108256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706101568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706110192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706111952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706109312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706110720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706236336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706234752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706237920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706233872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706236160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706243552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706245312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533739952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706100160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673706234224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533747168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533740480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533749104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533750864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533748224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533749632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533745408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533840544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533838080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533840368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533839664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533748752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533847584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533850752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533846352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533848992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533838784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533907488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533908544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533910304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533907664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533909072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533916816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533915232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533918400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533914000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533916640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673533908192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534023408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534026576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534022176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534024816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534033088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534029920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534099872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534101280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534109024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534107440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534110608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534106208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534108848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534115536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534183376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534186016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534182144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534184608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534192528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534185840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534194464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534196224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534193584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534194992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534183728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534283264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534286432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534282032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534284672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534294528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534292944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534290832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534291712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534294352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534368352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534361664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534370288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534372048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534369408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534370816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534371872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534493440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534495024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534504528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534502944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534506112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534501712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534504352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534494144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534595616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534596672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534598432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534595792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534597200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534603360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534606352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534641424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534650576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534648992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534652160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534647760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534650400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534604944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534592976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673534656208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399574720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399576480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399573840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399575248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399582992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399581408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399584576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399580176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399582816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399574368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399656816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399659984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399655584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399658224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399666496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399659808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399666320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399667728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399667552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399767456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399775200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399773616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399776784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399772384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399775024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399776608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399851312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399850784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399858704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399852016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399860640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399862400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399859760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399861168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673399859936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400180048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400184976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140673400185680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1758826593.746931    2644 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1758826593.746955    2644 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "Calibrating: 100%|██████████| 512/512 [02:46<00:00,  3.07it/s]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24784688"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# 如需全 INT8 I/O 接口（非必须）：\n",
    "# converter.inference_input_type = tf.int8\n",
    "# converter.inference_output_type = tf.int8\n",
    "tflite_int8 = converter.convert()\n",
    "open(\"resnet50_ptq_int8.tflite\", \"wb\").write(tflite_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119d420-9292-4f52-a11a-bdfb3a8a22c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46735f87-0593-4d78-84f1-6c5e7bfae730",
   "metadata": {},
   "source": [
    "# 5. QAT\n",
    "\n",
    "Insert fake quantization operators during training so the model learns to adapt to quantization errors. This approach typically achieves significantly better accuracy than PTQ.\n",
    "\n",
    "**Workflow:**\n",
    "1. Copy/initialize the FP32 model → apply fusion\n",
    "2. Set QAT qconfig (e.g., get_default_qat_qconfig(\"fbgemm\"))\n",
    "3. prepare_qat_fx → continue training for 5–20 epochs (much fewer than training from scratch)\n",
    "4. convert_fx → obtain the true INT8 quantized model\n",
    "5. Evaluate/benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb58001c-2a18-4022-b7d4-8d163a3d804b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ.pop(\"TF_USE_LEGACY_KERAS\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea6a0f1-2c9d-4c37-92c6-6cf9333fe28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "TF-MOT: 0.8.0\n",
      "Functional: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ.pop(\"TF_USE_LEGACY_KERAS\", None)  # 建议关闭 legacy 开关，避免奇怪兼容问题\n",
    "\n",
    "import tensorflow as tf, tensorflow_model_optimization as tfmot\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"TF-MOT:\", tfmot.__version__)\n",
    "print(\"Functional:\", getattr(model, \"_is_graph_network\", False))  # True 才能 QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7b1e0a-2bdd-4d36-97a2-466d529408c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863a755b-8fa7-4596-9075-176945fa8039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.keras import compat as kcompat\n",
    "\n",
    "# 1) 取出 TF-MOT 实际使用的 keras 命名空间（可能是 tf_keras）\n",
    "keras_q = kcompat.keras\n",
    "layers_q = keras_q.layers\n",
    "models_q = keras_q.models\n",
    "\n",
    "# 2) 用这一套 keras 重建同结构模型，并把你现有模型权重拷过去\n",
    "#    （你的现有模型是 `model`，来自 tensorflow.keras）\n",
    "inputs = keras_q.Input(shape=(224, 224, 3))\n",
    "base   = keras_q.applications.ResNet50V2(include_top=False, weights=None, pooling=\"avg\")\n",
    "x = base(inputs, training=False)\n",
    "x = layers_q.Dense(256, activation=\"relu\")(x)\n",
    "x = layers_q.Dropout(0.5)(x)\n",
    "outputs = layers_q.Dense(10, activation=\"softmax\")(x)\n",
    "model_q = models_q.Model(inputs, outputs, name=\"resnet50v2_cifar10_q\")\n",
    "\n",
    "# 拷贝权重（结构一致即可拷贝成功）\n",
    "model_q.set_weights(model.get_weights())\n",
    "\n",
    "# 3) 只量化“头部”两层（避免量化嵌套子模型）\n",
    "QuantizeAnnotate = tfmot.quantization.keras.quantize_annotate_layer\n",
    "QuantizeApply    = tfmot.quantization.keras.quantize_apply\n",
    "\n",
    "inp = model_q.input\n",
    "h   = base(inp, training=False)  # base 是上面同命名空间构建的子模型\n",
    "h   = QuantizeAnnotate(layers_q.Dense(256, activation=\"relu\", name=\"qa_fc\"))(h)\n",
    "h   = layers_q.Dropout(0.5)(h)\n",
    "out = QuantizeAnnotate(layers_q.Dense(10, activation=\"softmax\", name=\"qa_logits\"))(h)\n",
    "\n",
    "annotated = models_q.Model(inp, out, name=\"resnet50v2_head_qat\")\n",
    "qat_model = QuantizeApply(annotated)\n",
    "\n",
    "# 4) 冻结 BN 更稳（可选）\n",
    "for l in qat_model.layers:\n",
    "    if isinstance(l, layers_q.BatchNormalization):\n",
    "        l.trainable = False\n",
    "\n",
    "# 5) 编译训练\n",
    "qat_model.compile(\n",
    "    optimizer=keras_q.optimizers.Adam(1e-5),\n",
    "    loss=keras_q.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e32e4327-7b04-4c4a-8369-a5a32ddf2224",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== QAT Epoch 1/5 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 23:28:05.323215: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "2025-09-26 23:28:09.590331: I external/local_xla/xla/service/service.cc:163] XLA service 0x7faed4a488d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-26 23:28:09.590362: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA RTX A2000 12GB, Compute Capability 8.6\n",
      "2025-09-26 23:28:09.598451: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1758900489.756915     935 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 365s 403ms/step - loss: 0.9048 - accuracy: 0.6864 - val_loss: 0.2608 - val_accuracy: 0.9198\n",
      "\n",
      "==== QAT Epoch 2/5 ====\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.2605 - accuracy: 0.9216 - val_loss: 0.2345 - val_accuracy: 0.9316\n",
      "\n",
      "==== QAT Epoch 3/5 ====\n",
      " 62/782 [=>............................] - ETA: 4:30 - loss: 0.2078 - accuracy: 0.9337"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== QAT Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mqat_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# 一次只跑 1 个 epoch\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 显式告知步数\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "TRAIN_BS, TEST_BS = 64, 128\n",
    "EPOCHS = 2\n",
    "\n",
    "# 固定 test_ds（验证集只建一次）\n",
    "_, test_loader = make_torch_loaders(TRAIN_BS, TEST_BS)\n",
    "test_ds = make_tf_dataset_from_loader(test_loader, TEST_BS)\n",
    "val_steps = len(test_loader)\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    # 每个 epoch 重建 train_loader / train_ds\n",
    "    train_loader, _ = make_torch_loaders(TRAIN_BS, TEST_BS)\n",
    "    train_ds = make_tf_dataset_from_loader(train_loader, TRAIN_BS)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "\n",
    "    print(f\"\\n==== QAT Epoch {ep+1}/{EPOCHS} ====\")\n",
    "    qat_model.fit(\n",
    "        train_ds,\n",
    "        epochs=1,                         # 一次只跑 1 个 epoch\n",
    "        steps_per_epoch=steps_per_epoch,  # 显式告知步数\n",
    "        validation_data=test_ds,\n",
    "        validation_steps=val_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f9d81-c668-48ae-a47e-46516ef70151",
   "metadata": {},
   "source": [
    "==== QAT Epoch 1/5 ====\n",
    "782/782 [==============================] - 365s 403ms/step - loss: 0.9048 - accuracy: 0.6864 - val_loss: 0.2608 - val_accuracy: 0.9198\n",
    "\n",
    "==== QAT Epoch 2/5 ====\n",
    "782/782 [==============================] - 309s 396ms/step - loss: 0.2605 - accuracy: 0.9216 - val_loss: 0.2345 - val_accuracy: 0.9316\n",
    "\n",
    "==== QAT Epoch 3/5 ====\n",
    " 62/782 [=>............................] - ETA: 4:30 - loss: 0.2078 - accuracy: 0.9337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a676dbd-276c-4678-8671-eede67fea4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfcyt0xzx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfcyt0xzx/assets\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1758901242.453378     868 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1758901242.453429     868 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-09-26 23:40:42.453919: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpfcyt0xzx\n",
      "2025-09-26 23:40:42.505355: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-09-26 23:40:42.505409: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpfcyt0xzx\n",
      "I0000 00:00:1758901242.747376     868 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-09-26 23:40:42.785192: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-09-26 23:40:44.165408: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpfcyt0xzx\n",
      "2025-09-26 23:40:44.509301: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 2055392 microseconds.\n",
      "2025-09-26 23:43:43.505877: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2025-09-26 23:43:48.089839: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24815928"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 512\n",
    "def representative_gen():\n",
    "    for x,_ in test_ds.unbatch().take(N):\n",
    "        yield [tf.cast(tf.expand_dims(x,0), tf.float32)]\n",
    "\n",
    "conv = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
    "conv.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "conv.representative_dataset = representative_gen\n",
    "conv.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "tflite_qat = conv.convert()\n",
    "open(\"resnet50_qat_int8.tflite\",\"wb\").write(tflite_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2268f4-9969-4e8d-a3fe-4edd7fb9f3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dda74315-f626-4839-9a1f-1f9570e4e5da",
   "metadata": {},
   "source": [
    "# 6. Results Comparison (FP32 vs PTQ vs QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52cd36de-d9a4-4a32-94cb-f21cbd6f773d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ-dynamic ms P50/P90: [135.43599844 138.98892291]\n",
      "PTQ-int8   ms P50/P90: [120.72722614 124.73276444]\n",
      "QAT-int8   ms P50/P90: [120.73456123 125.14217161]\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np, tensorflow as tf\n",
    "\n",
    "def tflite_bench(tflite_path, sample):\n",
    "    inter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    inter.allocate_tensors()\n",
    "    inp = inter.get_input_details()[0][\"index\"]\n",
    "    out = inter.get_output_details()[0][\"index\"]\n",
    "    # 预热\n",
    "    for _ in range(20):\n",
    "        inter.set_tensor(inp, sample)\n",
    "        inter.invoke()\n",
    "    # 计时\n",
    "    ts=[]\n",
    "    for _ in range(200):\n",
    "        t0=time.perf_counter()\n",
    "        inter.set_tensor(inp, sample)\n",
    "        inter.invoke()\n",
    "        ts.append((time.perf_counter()-t0)*1000)\n",
    "    return np.percentile(ts,[50,90])\n",
    "\n",
    "# 取一小批样本做基准\n",
    "x_one, _ = next(iter(test_ds.take(1)))\n",
    "x_one = x_one[:1].numpy()\n",
    "print(\"PTQ-dynamic ms P50/P90:\", tflite_bench(\"resnet50_ptq_dynamic.tflite\", x_one))\n",
    "print(\"PTQ-int8   ms P50/P90:\", tflite_bench(\"resnet50_ptq_int8.tflite\", x_one))\n",
    "print(\"QAT-int8   ms P50/P90:\", tflite_bench(\"resnet50_qat_int8.tflite\", x_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4d381d-e5f9-448a-a9aa-caa62374b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 23:52:07.132290: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1520', 3420 bytes spill stores, 3344 bytes spill loads\n",
      "\n",
      "2025-09-26 23:52:44.911383: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-09-26 23:52:44.911448: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 4409749761582512711\n",
      "2025-09-26 23:52:44.911470: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 17874141467772767791\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary (threads: bench=4, acc=1; samples=5000 ) ===\n",
      "Model          Size(MB)       Top1    P50(ms)    P90(ms)\n",
      "FP32 (Keras)          -      92.53          -          -\n",
      "PTQ-dynamic       24.58      92.20      37.88      45.27\n",
      "PTQ-int8          24.78      89.82      33.46      39.35\n",
      "QAT-int8          24.82      91.02      31.95      37.93\n"
     ]
    }
   ],
   "source": [
    "import os, time, numpy as np, tensorflow as tf\n",
    "\n",
    "# ========= 通用工具 =========\n",
    "def _quantize_like(interpreter, x_float):\n",
    "    \"\"\"将 float32 NHWC 批量输入量化/或直喂，返回喂给 TFLite 的 numpy 数组。\"\"\"\n",
    "    d = interpreter.get_input_details()[0]\n",
    "    dtype = d[\"dtype\"]\n",
    "    if dtype == np.float32:\n",
    "        return x_float.astype(np.float32)\n",
    "    elif dtype == np.int8:\n",
    "        scale, zero = d[\"quantization\"]\n",
    "        # 将 float 量化成 int8；注意 clip 防溢出\n",
    "        return np.clip(np.round(x_float / scale + zero), -128, 127).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported input dtype: {dtype}\")\n",
    "\n",
    "def _dequantize_like(interpreter, y):\n",
    "    \"\"\"将 TFLite 输出（可能是 int8/float32）统一成 float32 概率/对数its。\"\"\"\n",
    "    d = interpreter.get_output_details()[0]\n",
    "    dtype = d[\"dtype\"]\n",
    "    if dtype == np.float32:\n",
    "        return y.astype(np.float32)\n",
    "    elif dtype == np.int8:\n",
    "        scale, zero = d[\"quantization\"]\n",
    "        return (y.astype(np.float32) - zero) * scale\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported output dtype: {dtype}\")\n",
    "\n",
    "# ========= TFLite 延迟测试 =========\n",
    "def tflite_bench(tflite_path, sample, runs=200, warmup=20, num_threads=1):\n",
    "    inter = tf.lite.Interpreter(model_path=tflite_path, num_threads=num_threads)\n",
    "    inter.allocate_tensors()\n",
    "    i_idx = inter.get_input_details()[0][\"index\"]\n",
    "    o_idx = inter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    x = _quantize_like(inter, sample)\n",
    "\n",
    "    # 预热\n",
    "    for _ in range(warmup):\n",
    "        inter.set_tensor(i_idx, x)\n",
    "        inter.invoke()\n",
    "\n",
    "    ts = []\n",
    "    for _ in range(runs):\n",
    "        t0 = time.perf_counter()\n",
    "        inter.set_tensor(i_idx, x)\n",
    "        inter.invoke()\n",
    "        _ = inter.get_tensor(o_idx)\n",
    "        ts.append((time.perf_counter() - t0) * 1000)\n",
    "    ts = np.array(ts)\n",
    "    return np.percentile(ts, [50, 90])\n",
    "\n",
    "# ========= TFLite Top-1 准确率 =========\n",
    "def tflite_top1_accuracy(tflite_path, ds, max_samples=None, num_threads=1):\n",
    "    inter = tf.lite.Interpreter(model_path=tflite_path, num_threads=num_threads)\n",
    "    inter.allocate_tensors()\n",
    "    i_idx = inter.get_input_details()[0][\"index\"]\n",
    "    o_idx = inter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    n_correct, n_total = 0, 0\n",
    "    for x, y in ds:\n",
    "        x_np = x.numpy()\n",
    "        y_np = y.numpy()\n",
    "        # 逐条推理（batch=1延迟更稳定；也可批量，但多数 TFLite 模型是 for b=1）\n",
    "        for i in range(x_np.shape[0]):\n",
    "            xi = x_np[i:i+1]\n",
    "            inter.set_tensor(i_idx, _quantize_like(inter, xi))\n",
    "            inter.invoke()\n",
    "            logits = _dequantize_like(inter, inter.get_tensor(o_idx))\n",
    "            pred = np.argmax(logits, axis=-1)[0]\n",
    "            n_correct += int(pred == int(y_np[i]))\n",
    "            n_total += 1\n",
    "            if (max_samples is not None) and (n_total >= max_samples):\n",
    "                acc = n_correct / n_total\n",
    "                return acc\n",
    "    acc = n_correct / max(n_total, 1)\n",
    "    return acc\n",
    "\n",
    "# ========= Keras Top-1 =========\n",
    "def keras_top1_accuracy(keras_model, ds):\n",
    "    res = keras_model.evaluate(ds, verbose=0, return_dict=True)\n",
    "    return float(res.get(\"accuracy\", res.get(\"acc\", 0.0)))\n",
    "\n",
    "# ========= 汇总评测 =========\n",
    "def bytes_mb(path): return os.path.getsize(path)/1e6 if os.path.exists(path) else None\n",
    "\n",
    "def evaluate_all(model_fp32, test_ds,\n",
    "                 tflite_dyn_path=\"resnet50_ptq_dynamic.tflite\",\n",
    "                 tflite_int8_path=\"resnet50_ptq_int8.tflite\",\n",
    "                 tflite_qat_path=\"resnet50_qat_int8.tflite\",\n",
    "                 bench_threads=1,\n",
    "                 acc_threads=1,\n",
    "                 acc_samples=None):\n",
    "    # 取一个样本做延迟评测（与预处理后的张量一致）\n",
    "    xb, yb = next(iter(test_ds.take(1)))\n",
    "    x_one = xb[:1].numpy()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 1) FP32 Keras\n",
    "    try:\n",
    "        acc = keras_top1_accuracy(model_fp32, test_ds)\n",
    "    except Exception as e:\n",
    "        acc = None\n",
    "        print(\"[WARN] Keras acc eval failed:\", e)\n",
    "    results.append({\n",
    "        \"name\": \"FP32 (Keras)\",\n",
    "        \"size_MB\": None,\n",
    "        \"acc\": acc,\n",
    "        \"p50_ms\": None,\n",
    "        \"p90_ms\": None\n",
    "    })\n",
    "\n",
    "    # 2) PTQ-dynamic\n",
    "    if os.path.exists(tflite_dyn_path):\n",
    "        acc = tflite_top1_accuracy(tflite_dyn_path, test_ds, max_samples=acc_samples, num_threads=acc_threads)\n",
    "        p50, p90 = tflite_bench(tflite_dyn_path, x_one, num_threads=bench_threads)\n",
    "        results.append({\n",
    "            \"name\": \"PTQ-dynamic\",\n",
    "            \"size_MB\": bytes_mb(tflite_dyn_path),\n",
    "            \"acc\": acc,\n",
    "            \"p50_ms\": float(p50),\n",
    "            \"p90_ms\": float(p90),\n",
    "        })\n",
    "\n",
    "    # 3) PTQ-int8\n",
    "    if os.path.exists(tflite_int8_path):\n",
    "        acc = tflite_top1_accuracy(tflite_int8_path, test_ds, max_samples=acc_samples, num_threads=acc_threads)\n",
    "        p50, p90 = tflite_bench(tflite_int8_path, x_one, num_threads=bench_threads)\n",
    "        results.append({\n",
    "            \"name\": \"PTQ-int8\",\n",
    "            \"size_MB\": bytes_mb(tflite_int8_path),\n",
    "            \"acc\": acc,\n",
    "            \"p50_ms\": float(p50),\n",
    "            \"p90_ms\": float(p90),\n",
    "        })\n",
    "\n",
    "    # 4) QAT-int8\n",
    "    if os.path.exists(tflite_qat_path):\n",
    "        acc = tflite_top1_accuracy(tflite_qat_path, test_ds, max_samples=acc_samples, num_threads=acc_threads)\n",
    "        p50, p90 = tflite_bench(tflite_qat_path, x_one, num_threads=bench_threads)\n",
    "        results.append({\n",
    "            \"name\": \"QAT-int8\",\n",
    "            \"size_MB\": bytes_mb(tflite_qat_path),\n",
    "            \"acc\": acc,\n",
    "            \"p50_ms\": float(p50),\n",
    "            \"p90_ms\": float(p90),\n",
    "        })\n",
    "\n",
    "    # 打印表格\n",
    "    print(\"\\n=== Summary (threads: bench={}, acc={}; samples={} ) ===\".format(\n",
    "        bench_threads, acc_threads, acc_samples if acc_samples else \"ALL\"))\n",
    "    print(\"{:<12} {:>10} {:>10} {:>10} {:>10}\".format(\"Model\", \"Size(MB)\", \"Top1\", \"P50(ms)\", \"P90(ms)\"))\n",
    "    for r in results:\n",
    "        print(\"{:<12} {:>10} {:>10} {:>10} {:>10}\".format(\n",
    "            r[\"name\"],\n",
    "            \"-\" if r[\"size_MB\"] is None else f\"{r['size_MB']:.2f}\",\n",
    "            \"-\" if r[\"acc\"] is None else f\"{r['acc']*100:.2f}\",\n",
    "            \"-\" if r[\"p50_ms\"] is None else f\"{r['p50_ms']:.2f}\",\n",
    "            \"-\" if r[\"p90_ms\"] is None else f\"{r['p90_ms']:.2f}\",\n",
    "        ))\n",
    "    return results\n",
    "\n",
    "# ========== 调用示例 ==========\n",
    "# 已有的：model（FP32 Keras 基线）、test_ds、三个 tflite 文件路径\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "results = evaluate_all(\n",
    "    model_fp32=model,\n",
    "    test_ds=test_ds,\n",
    "    tflite_dyn_path=\"resnet50_ptq_dynamic.tflite\",\n",
    "    tflite_int8_path=\"resnet50_ptq_int8.tflite\",\n",
    "    tflite_qat_path=\"resnet50_qat_int8.tflite\",\n",
    "    bench_threads=4,   \n",
    "    acc_threads=1,\n",
    "    acc_samples=5000,  # 为了速度可先抽样评估 5k 张\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876281a6-aae2-4ffa-9335-77b107786f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a3965a-299c-4c52-973b-ab7564367477",
   "metadata": {},
   "source": [
    "# 7. Model Export and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2471bafa-dda8-4d91-997f-c6273be1a73a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def representative_gen():\n",
    "    for x, _ in test_ds.take(200):  # 用 200 个 batch 作为代表性样本\n",
    "        for i in range(x.shape[0]):\n",
    "            yield [tf.cast(x[i:i+1], tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae75ca3-224d-46b1-933f-7ba4348166a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70693be1-ffd9-4b02-8085-4bf25d333ae7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq9idq8kz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq9idq8kz/assets\n",
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1758904392.994792     868 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1758904392.994845     868 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-09-27 00:33:12.995147: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpq9idq8kz\n",
      "2025-09-27 00:33:13.053817: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-09-27 00:33:13.053855: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpq9idq8kz\n",
      "2025-09-27 00:33:13.323445: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-09-27 00:33:14.701602: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpq9idq8kz\n",
      "2025-09-27 00:33:15.062202: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 2067059 microseconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m converter\u001b[38;5;241m.\u001b[39minference_input_type  \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m      8\u001b[0m converter\u001b[38;5;241m.\u001b[39minference_output_type \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint8\n\u001b[0;32m---> 10\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50_qat_int8.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     13\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1254\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1254\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1206\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1205\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1206\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1772\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \n\u001b[1;32m   1763\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1772\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_as_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1753\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1749\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1750\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir)\n\u001b[1;32m   1751\u001b[0m   )\n\u001b[1;32m   1752\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFLiteKerasModelConverterV2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1757\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1498\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m result \u001b[38;5;241m=\u001b[39m _convert_graphdef(\n\u001b[1;32m   1492\u001b[0m     input_data\u001b[38;5;241m=\u001b[39mgraph_def,\n\u001b[1;32m   1493\u001b[0m     input_tensors\u001b[38;5;241m=\u001b[39minput_tensors,\n\u001b[1;32m   1494\u001b[0m     output_tensors\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs,\n\u001b[1;32m   1496\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_tflite_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quant_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_build_conversion_flags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconverter_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_new_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1150\u001b[0m, in \u001b[0;36mTFLiteConverterBase._optimize_tflite_model\u001b[0;34m(self, model, quant_mode, debug_options, quant_io)\u001b[0m\n\u001b[1;32m   1148\u001b[0m   q_allow_float \u001b[38;5;241m=\u001b[39m quant_mode\u001b[38;5;241m.\u001b[39mis_allow_float()\n\u001b[1;32m   1149\u001b[0m   q_variable_quantization \u001b[38;5;241m=\u001b[39m quant_mode\u001b[38;5;241m.\u001b[39menable_mlir_variable_quantization\n\u001b[0;32m-> 1150\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_in_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_out_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_activations_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_bias_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_allow_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m      \u001b[49m\u001b[43mq_variable_quantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdebug_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m m_in_type \u001b[38;5;241m=\u001b[39m in_type \u001b[38;5;28;01mif\u001b[39;00m in_type \u001b[38;5;28;01melse\u001b[39;00m _dtypes\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m   1162\u001b[0m m_out_type \u001b[38;5;241m=\u001b[39m out_type \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;28;01melse\u001b[39;00m _dtypes\u001b[38;5;241m.\u001b[39mfloat32\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:761\u001b[0m, in \u001b[0;36mTFLiteConverterBase._quantize\u001b[0;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float, enable_variable_quantization, debug_options)\u001b[0m\n\u001b[1;32m    757\u001b[0m calibrate_quantize \u001b[38;5;241m=\u001b[39m _calibrator\u001b[38;5;241m.\u001b[39mCalibrator(\n\u001b[1;32m    758\u001b[0m     result, custom_op_registerers_by_name, custom_op_registerers_by_func\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_calibrate_only \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer:\n\u001b[0;32m--> 761\u001b[0m   calibrated \u001b[38;5;241m=\u001b[39m \u001b[43mcalibrate_quantize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentative_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_gen\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_calibrate_only:\n\u001b[1;32m    766\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m calibrated\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:258\u001b[0m, in \u001b[0;36mCalibrator.calibrate\u001b[0;34m(self, dataset_gen)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;129m@convert_phase\u001b[39m(Component\u001b[38;5;241m.\u001b[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001b[38;5;241m.\u001b[39mCALIBRATE)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalibrate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_gen):\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calibrates the model with specified generator.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    dataset_gen: A generator that generates calibration samples.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calibrator\u001b[38;5;241m.\u001b[39mCalibrate()\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:152\u001b[0m, in \u001b[0;36mCalibrator._feed_tensors\u001b[0;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calibrator\u001b[38;5;241m.\u001b[39mFeedTensor(input_array, signature_key)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calibrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeedTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# 输入/输出改为 int8\n",
    "converter.inference_input_type  = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"resnet50_qat_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56c49f7b-fa4c-44d2-adb6-40f74bb1d8c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "/tmp/ipykernel_868/3286000909.py:13: RuntimeWarning: divide by zero encountered in divide\n",
      "  x_quant = (x_one / scale + zero).astype(np.int8)\n",
      "/tmp/ipykernel_868/3286000909.py:13: RuntimeWarning: invalid value encountered in cast\n",
      "  x_quant = (x_one / scale + zero).astype(np.int8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type INT8 but expected type FLOAT32 for input 0, name: serving_default_input_5:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m scale, zero \u001b[38;5;241m=\u001b[39m inp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m x_quant \u001b[38;5;241m=\u001b[39m (x_one \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;241m+\u001b[39m zero)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint8)\n\u001b[0;32m---> 15\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor(out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:764\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type INT8 but expected type FLOAT32 for input 0, name: serving_default_input_5:0 "
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"resnet50_qat_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "inp = interpreter.get_input_details()[0]\n",
    "out = interpreter.get_output_details()[0]\n",
    "\n",
    "# 取 1 张 CIFAR-10 样本\n",
    "x_one, _ = next(iter(test_ds.take(1)))\n",
    "x_one = x_one[:1].numpy()\n",
    "\n",
    "# 按输入量化\n",
    "scale, zero = inp[\"quantization\"]\n",
    "x_quant = (x_one / scale + zero).astype(np.int8)\n",
    "\n",
    "interpreter.set_tensor(inp[\"index\"], x_quant)\n",
    "interpreter.invoke()\n",
    "y_pred = interpreter.get_tensor(out[\"index\"])\n",
    "print(\"Predicted:\", y_pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8826df6-7d0f-4daa-859a-4bf3b50c6437",
   "metadata": {},
   "source": [
    "## 1. TorchScript（CPU inference）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf736853-9e9d-437a-bcec-5582e027ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/export.py\n",
    "import torch\n",
    "m_int8 = ...  # 加载 PTQ 或 QAT 模型到 CPU\n",
    "m_int8.eval()\n",
    "example = torch.randn(1,3,32,32)\n",
    "ts = torch.jit.trace(m_int8, example)\n",
    "ts = torch.jit.freeze(ts)\n",
    "ts.save(\"results/resnet18_int8_ts.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d979b71-1152-4237-a30f-c710d73cd3b2",
   "metadata": {},
   "source": [
    "## 2. ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93276820-f12f-4856-8ee7-a8f9462389bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(m_int8, example, \"results/resnet18_int8.onnx\",\n",
    "                  input_names=[\"input\"], output_names=[\"logits\"],\n",
    "                  opset_version=17, dynamic_axes={\"input\":{0:\"N\"}, \"logits\":{0:\"N\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616a77c-20df-4cc3-b585-dc7797217333",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e80c0-cea8-4595-ba31-92d10397435f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4568-453d-4ba2-98c2-85c332cea082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
